# DOCUMENTO 3 v2: MANUAL OPERATIVO DE MIGRACI√ìN

**Sistema:** E.D.N.360 - Migraci√≥n AS IS ‚Üí TO BE (Client Drawer)  
**Tipo:** Manual de Ejecuci√≥n Obligatorio  
**Fecha:** Enero 2025  
**Versi√≥n:** 2.0 FINAL  
**Estado:** Pendiente de aprobaci√≥n formal  
**Referencia:** Documento 2 vFINAL (Aprobado)  

---

## ‚ö†Ô∏è ADVERTENCIA CR√çTICA

Este documento es un **manual de ejecuci√≥n obligatorio**, no una gu√≠a orientativa.

**Ninguna fase puede ejecutarse sin:**
1. Cumplir √≠ntegramente los requisitos especificados
2. Superar los criterios de validaci√≥n establecidos
3. Obtener aprobaci√≥n formal de Jorge Calcerrada en los puntos GO/NO-GO

**Desviaci√≥n de este manual = suspensi√≥n inmediata de la migraci√≥n.**

---

## üìã √çNDICE

### PARTE 1: FUNDAMENTOS
1. [Modelo de Cuestionario √önico EDN360](#1-modelo-cuestionario-√∫nico)
2. [Mapa Contractual Legacy ‚Üí TO BE](#2-mapa-contractual)
3. [Estrategia Oficial Anti-Duplicados](#3-estrategia-anti-duplicados)

### PARTE 2: FASES DE EJECUCI√ìN
4. [Fase 0: Preparaci√≥n](#4-fase-0-preparaci√≥n)
5. [Fase 0.5: STAGING (OBLIGATORIA)](#5-fase-05-staging)
6. [Fase 1: Coexistencia Dual-Write](#6-fase-1-coexistencia)
7. [Fase 2: Migraci√≥n Hist√≥rica](#7-fase-2-migraci√≥n)
8. [Fase 3: Switch a Client Drawer](#8-fase-3-switch)
9. [Fase 4: Limpieza Legacy](#9-fase-4-limpieza)

### PARTE 3: OPERATIVA Y CONTROL
10. [Tabla de Umbrales y Acciones](#10-umbrales-y-acciones)
11. [Listado Completo de Scripts](#11-listado-scripts)
12. [Plan de Rollback](#12-plan-rollback)
13. [Puntos de Supervisi√≥n Jorge](#13-supervisi√≥n-jorge)
14. [Criterios de Cierre T√©cnico](#14-cierre-t√©cnico)

---

## 1. MODELO CUESTIONARIO √öNICO

### üéØ Realidad Cl√≠nica

**PRINCIPIO FUNDAMENTAL:**

> En EDN360 **NO existen cuestionarios separados por dominio** (entrenamiento/nutrici√≥n).

**Solo existen 2 tipos de cuestionarios:**

1. **Cuestionario Inicial (Anamnesis EDN360):**
   - Una √∫nica captura integral del cliente
   - Incluye datos de entrenamiento Y nutrici√≥n
   - Una sola fecha de submission por cliente

2. **Cuestionario de Seguimiento (Seguimiento EDN360):**
   - Una √∫nica evaluaci√≥n de progreso integral
   - Incluye adherencia y cambios en entrenamiento Y nutrici√≥n
   - Una sola fecha de submission por seguimiento

**Cualquier referencia a "cuestionario de entrenamiento" o "cuestionario de nutrici√≥n" como entidades separadas es incorrecta y debe eliminarse.**

---

### üìê Estructura TO BE Oficial

```javascript
client_drawer = {
  _id: "client_1762094831193507",
  user_id: "1762094831193507",
  
  profile: {
    // Datos personales globales
    nombre_completo: "Jorge Calcerrada",
    email: "jorge@example.com",
    // ...
  },
  
  services: {
    // ============================================
    // SHARED: Cuestionarios √∫nicos EDN360
    // ============================================
    shared: {
      questionnaires: {
        // Cuestionario inicial √∫nico
        inicial: {
          submitted_at: ISODate("2025-01-02T09:00:00Z"),
          version: "1.0.0",
          schema_version: "questionnaire_edn360_v1",
          
          // Secci√≥n de entrenamiento
          training_section: {
            personal_data: { /* ... */ },
            measurements: { /* ... */ },
            health: { /* ... */ },
            work_life: { /* ... */ },
            sports_background: { /* ... */ },
            availability: { /* ... */ },
            daily_schedule: { /* ... */ },
            goals: {
              primary_objective: "Perder grasa"  // ‚≠ê
            }
          },
          
          // Secci√≥n de nutrici√≥n
          nutrition_section: {
            nutrition_habits: { /* ... */ },
            preferences: { /* ... */ },
            diet_history: { /* ... */ },
            eating_patterns: { /* ... */ }
          }
        },
        
        // Seguimientos √∫nicos
        followups: [
          {
            followup_id: "followup_feb2025",
            submitted_at: ISODate("2025-02-03T10:00:00Z"),
            days_since_last: 30,
            previous_snapshot_training_id: "snapshot_training_v1",
            previous_snapshot_nutrition_id: "snapshot_nutrition_v1",
            
            // Secci√≥n de entrenamiento
            training_section: {
              measurements: { peso: "83", grasa: "20" },
              adherence: { constancia_entrenamiento: "80%" },
              changes_perceived: { fuerza: "Mejorando" },
              feedback: { objetivo_proximo_mes: "Seguir perdiendo grasa" }
            },
            
            // Secci√≥n de nutrici√≥n
            nutrition_section: {
              adherence: { seguimiento_alimentacion: "70%" },
              changes_perceived: { saciedad: "Buena" },
              feedback: { cambios_deseados: "M√°s variedad de recetas" }
            }
          }
        ]
      }
    },
    
    // ============================================
    // TRAINING: Snapshots y planes de entrenamiento
    // ============================================
    training: {
      active: true,
      enrolled_at: ISODate("2025-01-02T09:00:00Z"),
      
      snapshots: [
        {
          snapshot_id: "snapshot_training_v1",
          version: 1,
          created_at: ISODate("2025-01-03T10:15:30Z"),
          trigger: "inicial",
          
          // ClientContext de entrenamiento
          client_context: {
            training: {
              client_summary: { /* E1 */ },
              profile: { /* E1 */ },
              constraints: { /* E1 */ },
              capacity: { /* E2 */ },
              mesocycle: { /* E4 */ },
              sessions: [ /* E5 */ ],
              // ... E1-E9 outputs
            }
          },
          
          plans_generated: {
            training_plan_id: "training_v1_jan2025"
          }
        }
      ],
      
      plans: [
        {
          plan_id: "training_v1_jan2025",
          version: 1,
          snapshot_id: "snapshot_training_v1",
          generated_at: ISODate("2025-01-03T10:15:20Z"),
          status: "active"
        }
      ],
      
      measurements: [],  // Si aplica medidas espec√≠ficas de entreno
      notes: []
    },
    
    // ============================================
    // NUTRITION: Snapshots y planes de nutrici√≥n
    // ============================================
    nutrition: {
      active: true,
      enrolled_at: ISODate("2025-01-02T09:00:00Z"),
      
      snapshots: [
        {
          snapshot_id: "snapshot_nutrition_v1",
          version: 1,
          created_at: ISODate("2025-01-03T10:15:35Z"),
          trigger: "inicial",
          
          // ClientContext de nutrici√≥n
          client_context: {
            nutrition: {
              profile: { /* N0 */ },
              metabolism: { /* N1 */ },
              macro_design: { /* N3 */ },
              // ... N0-N8 outputs
            }
          },
          
          plans_generated: {
            nutrition_plan_id: "nutrition_v1_jan2025"
          }
        }
      ],
      
      plans: [
        {
          plan_id: "nutrition_v1_jan2025",
          version: 1,
          snapshot_id: "snapshot_nutrition_v1",
          generated_at: ISODate("2025-01-03T10:15:25Z"),
          status: "active"
        }
      ],
      
      measurements: [],
      notes: []
    }
  },
  
  meta: {
    created_at: ISODate("2025-01-02T09:00:00Z"),
    updated_at: ISODate("2025-02-03T11:00:30Z"),
    active_services: ["training", "nutrition"],
    has_archived_snapshots: false,
    status: "active"
  }
}
```

---

### üîÑ Uso por Pipeline

**Pipeline de Entrenamiento (E1-E9):**

Lee datos de:
```python
training_data = client_drawer["services"]["shared"]["questionnaires"]["inicial"]["training_section"]
```

**Pipeline de Nutrici√≥n (N0-N8):**

Lee datos de:
```python
nutrition_data = client_drawer["services"]["shared"]["questionnaires"]["inicial"]["nutrition_section"]
```

**Snapshots y planes:**
- Se mantienen separados por dominio
- `services.training.snapshots[]` para entrenamiento
- `services.nutrition.snapshots[]` para nutrici√≥n

---

## 2. MAPA CONTRACTUAL

### üìã Tabla Oficial: Colecciones Legacy ‚Üí Client Drawer

Esta tabla es el **contrato oficial de migraci√≥n**. No admite interpretaciones.

| **Colecci√≥n Legacy** | **Servicio Destino** | **Ruta en Client Drawer** | **Tipo de Dato** |
|---|---|---|---|
| `questionnaire_responses` | `shared` | `services.shared.questionnaires.inicial` | Anamnesis EDN360 (cuestionario inicial √∫nico) |
| `followup_submissions` | `shared` | `services.shared.questionnaires.followups[]` | Seguimiento integral EDN360 |
| `training_plans` | `training` | `services.training.plans[]` | Plan hist√≥rico de entrenamiento |
| `nutrition_plans` | `nutrition` | `services.nutrition.plans[]` | Plan hist√≥rico de nutrici√≥n |

**Notas:**

1. **`questionnaire_responses` vs `nutrition_questionnaire_submissions`:**
   - En el sistema actual puede haber dos colecciones con nombres distintos
   - Ambas deben consolidarse en `services.shared.questionnaires.inicial`
   - La migraci√≥n unificar√° estos datos

2. **`followup_submissions`:**
   - Puede haber seguimientos solo de training, solo de nutrition, o completos
   - Todos van a `services.shared.questionnaires.followups[]`
   - Cada seguimiento tiene `training_section` y/o `nutrition_section`

3. **Planes hist√≥ricos:**
   - Los planes se mantienen en sus servicios respectivos
   - NO se duplican cuestionarios en planes
   - Planes referencian snapshots via `snapshot_id`

---

## 3. ESTRATEGIA ANTI-DUPLICADOS

### üîí Estrategia Oficial Aprobada

**Declaraci√≥n formal:**

> "Estrategia oficial aprobada para la migraci√≥n de datos hist√≥ricos:  
> **Cutoff por fecha (`dual_write_start_at`) + Checks de idempotencia por IDs l√≥gicos**"

---

### üìÖ Par√°metro Cr√≠tico: `dual_write_start_at`

**Definici√≥n:**

```python
# /app/backend/config.py

class MigrationConfig:
    # Timestamp exacto de inicio del dual-write
    # TODO: Definir antes de ejecutar Fase 1
    DUAL_WRITE_START_AT = datetime(2025, 2, 1, 0, 0, 0, tzinfo=timezone.utc)
    
    # Feature flags
    USE_CLIENT_DRAWER_WRITE = os.getenv("USE_CLIENT_DRAWER_WRITE", "false").lower() == "true"
    USE_CLIENT_DRAWER_READ = os.getenv("USE_CLIENT_DRAWER_READ", "false").lower() == "true"
```

**Uso:**

- **Fase 1 (Dual-Write):** Todos los nuevos cuestionarios con `submitted_at >= DUAL_WRITE_START_AT` se escriben en ambos sistemas (legacy + drawer)
- **Fase 2 (Migraci√≥n Batch):** Solo migra registros con `submitted_at < DUAL_WRITE_START_AT`

---

### ‚úÖ Reglas de No Duplicaci√≥n

#### Regla 1: Cutoff Temporal

```python
# En scripts de Fase 2

# Migrar solo registros hist√≥ricos (antes del dual-write)
submissions_to_migrate = await db.nutrition_questionnaire_submissions.find({
    "submitted_at": {"$lt": MigrationConfig.DUAL_WRITE_START_AT}
}).to_list(100000)

# Los submissions con submitted_at >= DUAL_WRITE_START_AT ya est√°n en drawer
# NO los volvemos a migrar
```

#### Regla 2: Idempotencia por IDs L√≥gicos

Antes de insertar en `client_drawers`, verificar existencia:

```python
# Verificar si cuestionario inicial ya existe
existing_drawer = await db.client_drawers.find_one({
    "user_id": user_id,
    "services.shared.questionnaires.inicial": {"$exists": True}
})

if existing_drawer:
    logger.info(f"‚úÖ Drawer {user_id} already has inicial questionnaire (skipping)")
    continue  # No duplicar

# Verificar followup_id
existing_followup = await db.client_drawers.find_one({
    "user_id": user_id,
    "services.shared.questionnaires.followups.followup_id": followup_id
})

if existing_followup:
    logger.info(f"‚úÖ Followup {followup_id} already exists (skipping)")
    continue

# Verificar measurement_id (si aplica)
existing_measurement = await db.client_drawers.find_one({
    "user_id": user_id,
    "services.training.measurements.measurement_id": measurement_id
})

# Etc.
```

#### Regla 3: Validaci√≥n Post-Migraci√≥n

```python
# Despu√©s de Fase 2, verificar coherencia de contadores

# Total submissions legacy antes del cutoff
legacy_count = await db.nutrition_questionnaire_submissions.count_documents({
    "submitted_at": {"$lt": MigrationConfig.DUAL_WRITE_START_AT}
})

# Total drawers con cuestionario inicial
drawer_count = await db.client_drawers.count_documents({
    "services.shared.questionnaires.inicial": {"$exists": True}
})

# Debe ser: drawer_count >= legacy_count * 0.95
assert drawer_count >= legacy_count * 0.95, "Migration incomplete: too few drawers"
```

---

### üö® Detecci√≥n de Duplicados

**Script de validaci√≥n:**

```python
# /app/backend/migration/scripts/detect_duplicates.py

async def detect_duplicates_in_drawers():
    """
    Detecta duplicados en drawers despu√©s de migraci√≥n.
    
    Si encuentra > 0 duplicados: PAUSA INMEDIATA.
    """
    
    duplicates = []
    
    # Verificar followups duplicados (mismo followup_id)
    drawers = await db.client_drawers.find({}).to_list(100000)
    
    for drawer in drawers:
        followups = drawer["services"]["shared"]["questionnaires"].get("followups", [])
        followup_ids = [f["followup_id"] for f in followups]
        
        # Detectar duplicados
        seen = set()
        for fid in followup_ids:
            if fid in seen:
                duplicates.append({
                    "client_id": drawer["_id"],
                    "duplicate_followup_id": fid
                })
            seen.add(fid)
    
    if duplicates:
        logger.error(f"‚ùå DUPLICATES DETECTED: {len(duplicates)}")
        for dup in duplicates:
            logger.error(f"  - {dup}")
        
        raise Exception("MIGRATION PAUSED: Duplicates detected")
    
    logger.info("‚úÖ No duplicates found")
    return duplicates
```

---

## 4. FASE 0: PREPARACI√ìN

### üéØ Objetivo

Crear infraestructura TO BE sin afectar producci√≥n.

---

### üìã Tareas

#### 4.1. Crear Modelos Pydantic

**Archivo:** `/app/backend/models/client_drawer.py`

**Modelo principal:**

```python
class SharedQuestionnaires(BaseModel):
    """Cuestionarios √∫nicos EDN360 (training + nutrition)"""
    inicial: Optional[QuestionnaireInicial] = None
    followups: List[QuestionnaireFollowup] = Field(default_factory=list)

class QuestionnaireInicial(BaseModel):
    submitted_at: datetime
    version: str = "1.0.0"
    schema_version: str = "questionnaire_edn360_v1"
    training_section: Dict[str, Any]
    nutrition_section: Dict[str, Any]

class ServiceShared(BaseModel):
    """Servicio compartido para cuestionarios √∫nicos"""
    questionnaires: SharedQuestionnaires = Field(default_factory=SharedQuestionnaires)

class ClientServices(BaseModel):
    shared: ServiceShared = Field(default_factory=ServiceShared)
    training: ServiceModule = Field(default_factory=ServiceModule)
    nutrition: ServiceModule = Field(default_factory=ServiceModule)

class ClientDrawer(BaseModel):
    client_drawer_id: str = Field(alias="_id")
    user_id: str
    profile: ClientProfile
    services: ClientServices = Field(default_factory=ClientServices)
    meta: Dict[str, Any]
```

---

#### 4.2. Crear Colecci√≥n `client_drawers`

**Script:** `/app/backend/migration/scripts/00_create_collection.py`

```python
async def create_client_drawers_collection():
    """Crear colecci√≥n con √≠ndices"""
    
    # Crear colecci√≥n
    await db.create_collection("client_drawers")
    
    # √çndices
    await db.client_drawers.create_index("user_id", unique=True)
    await db.client_drawers.create_index("services.shared.questionnaires.inicial.submitted_at")
    await db.client_drawers.create_index("services.training.active")
    await db.client_drawers.create_index("services.nutrition.active")
    
    print("‚úÖ Collection created with indexes")
```

**Ejecuci√≥n:**
```bash
python /app/backend/migration/scripts/00_create_collection.py
```

---

#### 4.3. Tests Unitarios

**Archivo:** `/app/backend/tests/test_client_drawer_model.py`

```python
def test_shared_questionnaires_structure():
    """Test: Estructura de cuestionarios compartidos"""
    drawer = ClientDrawer(
        client_drawer_id="client_test",
        user_id="test",
        profile=ClientProfile(...),
        services=ClientServices(
            shared=ServiceShared(
                questionnaires=SharedQuestionnaires(
                    inicial=QuestionnaireInicial(
                        submitted_at=datetime.now(),
                        training_section={"goals": {"primary_objective": "Perder grasa"}},
                        nutrition_section={"preferences": {}}
                    )
                )
            )
        ),
        meta={}
    )
    
    assert drawer.services.shared.questionnaires.inicial is not None
    assert "training_section" in drawer.services.shared.questionnaires.inicial.dict()
    assert "nutrition_section" in drawer.services.shared.questionnaires.inicial.dict()
```

---

### ‚úÖ Criterios de Validaci√≥n Fase 0

| **Criterio** | **Validaci√≥n** |
|---|---|
| Modelos Pydantic con `services.shared` | Tests unitarios pasan |
| Colecci√≥n `client_drawers` creada | Query MongoDB exitoso |
| √çndices correctos | 4+ √≠ndices verificados |

### üîÑ Rollback Fase 0

N/A - Sin impacto en producci√≥n.

### ‚è±Ô∏è Duraci√≥n Estimada

**3-5 d√≠as** (tras aprobaci√≥n formal del documento)

---

## 5. FASE 0.5: STAGING

### üéØ Objetivo

**Fase obligatoria:** Simular migraci√≥n completa en entorno aislado antes de tocar producci√≥n.

---

### ‚ö†Ô∏è REGLA DE BLOQUEO

> **"Sin superar la FASE 0.5 en staging con resultados aceptables, NO se autoriza la ejecuci√≥n de Fase 2 ni Fase 3 en producci√≥n."**

---

### üìã Requisitos de Entrada

1. **Dump reciente de producci√≥n:**
   ```bash
   # Crear dump de BD de producci√≥n
   mongodump --uri="$PROD_MONGO_URL" --db="$PROD_DB_NAME" --out=/backups/staging_dump_$(date +%Y%m%d)
   ```

2. **Entorno staging configurado:**
   - MongoDB staging aislado
   - Backend staging con c√≥digo id√©ntico a prod
   - Variables de entorno staging

3. **Restaurar dump en staging:**
   ```bash
   mongorestore --uri="$STAGING_MONGO_URL" --db="staging_db" /backups/staging_dump_YYYYMMDD
   ```

---

### üìã Ejecuci√≥n en Staging

Ejecutar **de principio a fin** las siguientes fases:

1. **Fase 0:** Crear `client_drawers`, √≠ndices, modelos
2. **Fase 1:** Activar dual-write en staging
3. **Fase 2:** Ejecutar migraci√≥n hist√≥rica completa
4. **Fase 3:** Switch de lectura a `client_drawers`

**Usando los mismos scripts, flags y par√°metros que se usar√°n en producci√≥n.**

---

### üìä Output Obligatorio de Staging

Al finalizar, debe existir un **informe de staging** con:

#### M√©tricas de Tiempo

| **Script** | **Duraci√≥n** | **Tiempo/Batch** |
|---|---|---|
| 02_migrate_questionnaires.py | 2h 15min | 45s / 1000 registros |
| 03_migrate_followups.py | 1h 30min | 30s / 1000 registros |
| 04_migrate_legacy_plans.py | 3h 45min | 60s / 1000 planes |

#### Volumen de Datos Migrados

| **Tipo** | **Total Legacy** | **Migrado** | **Match Rate** |
|---|---|---|---|
| Cuestionarios iniciales | 15,234 | 15,180 | 99.6% |
| Followups | 8,456 | 8,420 | 99.5% |
| Training plans | 12,890 | 12,850 | 99.7% |
| Nutrition plans | 12,890 | 12,850 | 99.7% |

#### Errores y Correcciones

```
Errores detectados en staging:
1. Error: 54 cuestionarios con campos faltantes
   - Correcci√≥n: Script ajustado para manejar valores null
   
2. Error: 12 planes sin user_id v√°lido
   - Correcci√≥n: Filtro a√±adido en migraci√≥n

3. Error: Timeout en batch de 5000 registros
   - Correcci√≥n: Tama√±o de batch reducido a 1000
```

#### Ajustes Aplicados

```
Optimizaciones aplicadas tras staging:
- √çndice adicional en submitted_at (mejora 40% velocidad)
- Batch size reducido de 5000 ‚Üí 1000 (evita timeouts)
- Timeout aumentado de 60s ‚Üí 120s en scripts
```

---

### ‚úÖ Criterios de Aprobaci√≥n Staging

| **Criterio** | **Umbral** | **Estado** |
|---|---|---|
| Match rate cuestionarios | ‚â• 95% | ‚è≥ |
| Match rate followups | ‚â• 95% | ‚è≥ |
| Match rate planes | ‚â• 90% | ‚è≥ |
| Errores cr√≠ticos | 0 | ‚è≥ |
| Duplicados detectados | 0 | ‚è≥ |

**Solo con TODOS los criterios en ‚úÖ se aprueba pasar a producci√≥n.**

---

### üîÑ Rollback Staging

Si staging falla:
1. No afecta producci√≥n (entorno aislado)
2. Corregir scripts
3. Re-ejecutar staging desde cero
4. Repetir hasta superar criterios

---

### ‚è±Ô∏è Duraci√≥n Estimada

**5-7 d√≠as:**
- Setup staging: 1 d√≠a
- Ejecuci√≥n completa: 2-3 d√≠as
- An√°lisis y ajustes: 2-3 d√≠as

---

## 6. FASE 1: COEXISTENCIA

### üéØ Objetivo

Escribir en AMBOS sistemas (AS IS + TO BE) sin cambiar la lectura.

---

### üìÖ Definir `DUAL_WRITE_START_AT`

**Antes de activar Fase 1, definir:**

```python
# /app/backend/config.py

class MigrationConfig:
    # Ejemplo: 1 de Febrero 2025, 00:00:00 UTC
    DUAL_WRITE_START_AT = datetime(2025, 2, 1, 0, 0, 0, tzinfo=timezone.utc)
```

**Este timestamp marca la frontera:**
- Antes: Se migrar√° en Fase 2
- Despu√©s: Se gestiona por dual-write

---

### üìã Tareas

#### 6.1. Implementar Dual-Write

**Script:** `/app/backend/migration/scripts/01_enable_dual_write.py`

**Modificar endpoint:**

```python
# /app/backend/server.py

@app.post("/api/questionnaire/submit")
async def submit_questionnaire(user_id: str, responses: Dict):
    """
    Submission de cuestionario EDN360 (√∫nico).
    
    FASE 1: Dual-write mode activo.
    """
    
    # ========================================
    # ESCRITURA AS IS (Legacy)
    # ========================================
    submission = {
        "_id": f"submission_{uuid.uuid4()}",
        "user_id": user_id,
        "responses": responses,  # Dict plano
        "submitted_at": datetime.now(timezone.utc),
        "plan_generated": False
    }
    
    await db.nutrition_questionnaire_submissions.insert_one(submission)
    logger.info(f"‚úÖ Written to AS IS: {submission['_id']}")
    
    # ========================================
    # ESCRITURA TO BE (Client Drawer)
    # ========================================
    if Config.USE_CLIENT_DRAWER_WRITE:
        try:
            # Separar responses en secciones training/nutrition
            training_section = extract_training_section(responses)
            nutrition_section = extract_nutrition_section(responses)
            
            # Construir cuestionario inicial
            questionnaire_inicial = {
                "submitted_at": datetime.now(timezone.utc),
                "version": "1.0.0",
                "schema_version": "questionnaire_edn360_v1",
                "training_section": training_section,
                "nutrition_section": nutrition_section
            }
            
            # Extraer profile
            profile = extract_profile(responses)
            
            # Upsert client_drawer
            await db.client_drawers.update_one(
                {"user_id": user_id},
                {
                    "$set": {
                        "profile": profile,
                        "services.shared.questionnaires.inicial": questionnaire_inicial,
                        "meta.updated_at": datetime.now(timezone.utc)
                    },
                    "$setOnInsert": {
                        "_id": f"client_{user_id}",
                        "user_id": user_id,
                        "services.training.active": True,
                        "services.nutrition.active": True,
                        "meta.created_at": datetime.now(timezone.utc),
                        "meta.active_services": ["training", "nutrition"],
                        "meta.status": "active"
                    }
                },
                upsert=True
            )
            
            logger.info(f"‚úÖ Written to TO BE: client_{user_id}")
            
            # Validaci√≥n background
            asyncio.create_task(validate_dual_write(user_id, submission["_id"]))
        
        except Exception as e:
            logger.error(f"‚ùå Error writing to TO BE: {e}")
            # NO FALLAR: AS IS ya se escribi√≥
    
    return {"status": "success", "submission_id": submission["_id"]}
```

---

#### 6.2. Activar Feature Flag

```bash
# .env
USE_CLIENT_DRAWER_WRITE=true
USE_CLIENT_DRAWER_READ=false  # Lectura sigue en AS IS

# Reiniciar
sudo supervisorctl restart backend
```

---

#### 6.3. Monitoreo

**Dashboard:**

```python
@app.get("/admin/monitoring/dual-write-stats")
async def get_dual_write_stats():
    total = await db.dual_write_validations.count_documents({})
    matching = await db.dual_write_validations.count_documents({"match": True})
    
    return {
        "total_validations": total,
        "matching": matching,
        "match_rate": matching / total if total > 0 else 0
    }
```

---

### ‚úÖ Criterios de Validaci√≥n Fase 1

| **Criterio** | **Umbral** |
|---|---|
| Match rate | > 98% |
| Sin errores cr√≠ticos | 0 |

### üîÑ Rollback Fase 1

```bash
# Desactivar
USE_CLIENT_DRAWER_WRITE=false
sudo supervisorctl restart backend
```

**Tiempo:** < 2 minutos

---

### ‚è±Ô∏è Duraci√≥n Estimada

**1-2 semanas** (monitoreo + ajustes)

---

## 7. FASE 2: MIGRACI√ìN

### üéØ Objetivo

Migrar datos hist√≥ricos (`submitted_at < DUAL_WRITE_START_AT`) a `client_drawers`.

---

### üîí BACKUP OBLIGATORIO

**Antes de ejecutar Fase 2:**

```bash
# Script: /app/backend/migration/scripts/backup_full_database.sh

#!/bin/bash
BACKUP_DIR="/backups/pre_phase2_$(date +%Y%m%d_%H%M%S)"
mkdir -p $BACKUP_DIR

mongodump --uri="$MONGO_URL" --db="$DB_NAME" --out="$BACKUP_DIR"

echo "‚úÖ Backup: $BACKUP_DIR"
du -sh $BACKUP_DIR
```

**Verificar que backup existe y tiene tama√±o > 0 antes de continuar.**

---

### üìã Migraci√≥n por Tipo

#### 7.1. Migrar Cuestionarios Iniciales

**Script:** `/app/backend/migration/scripts/02_migrate_questionnaires.py`

```python
async def migrate_questionnaires():
    """
    Migrar cuestionarios iniciales a services.shared.questionnaires.inicial
    
    REGLA: Solo migrar submitted_at < DUAL_WRITE_START_AT
    """
    
    cutoff = MigrationConfig.DUAL_WRITE_START_AT
    
    # Obtener submissions legacy antes del cutoff
    submissions = await db.nutrition_questionnaire_submissions.find({
        "submitted_at": {"$lt": cutoff}
    }).to_list(100000)
    
    total = len(submissions)
    migrated = 0
    skipped = 0
    errors = []
    
    for submission in submissions:
        try:
            user_id = submission["user_id"]
            
            # CHECK DE IDEMPOTENCIA
            existing = await db.client_drawers.find_one({
                "user_id": user_id,
                "services.shared.questionnaires.inicial": {"$exists": True}
            })
            
            if existing:
                logger.info(f"‚è≠Ô∏è Skipped {user_id}: inicial already exists")
                skipped += 1
                continue
            
            # Separar en secciones
            training_section = extract_training_section(submission["responses"])
            nutrition_section = extract_nutrition_section(submission["responses"])
            
            # Construir cuestionario
            questionnaire = {
                "submitted_at": submission.get("submitted_at"),
                "version": "1.0.0",
                "schema_version": "questionnaire_edn360_v1",
                "training_section": training_section,
                "nutrition_section": nutrition_section
            }
            
            # Profile
            profile = extract_profile(submission["responses"])
            
            # Upsert drawer
            await db.client_drawers.update_one(
                {"user_id": user_id},
                {
                    "$set": {
                        "profile": profile,
                        "services.shared.questionnaires.inicial": questionnaire,
                        "services.training.active": True,
                        "services.nutrition.active": True,
                        "meta.updated_at": datetime.now(timezone.utc)
                    },
                    "$setOnInsert": {
                        "_id": f"client_{user_id}",
                        "user_id": user_id,
                        "meta.created_at": submission.get("submitted_at"),
                        "meta.active_services": ["training", "nutrition"],
                        "meta.status": "active"
                    }
                },
                upsert=True
            )
            
            migrated += 1
            
            if migrated % 100 == 0:
                logger.info(f"Progress: {migrated}/{total}")
        
        except Exception as e:
            logger.error(f"Error: {submission['_id']}: {e}")
            errors.append({"submission_id": submission["_id"], "error": str(e)})
    
    logger.info(f"""
    ‚úÖ Questionnaires migration:
    - Total: {total}
    - Migrated: {migrated}
    - Skipped: {skipped}
    - Errors: {len(errors)}
    """)
    
    return {"total": total, "migrated": migrated, "skipped": skipped, "errors": errors}
```

---

#### 7.2. Migrar Followups

**Script:** `/app/backend/migration/scripts/03_migrate_followups.py`

```python
async def migrate_followups():
    """
    Migrar followups a services.shared.questionnaires.followups[]
    
    REGLA: Solo migrar submitted_at < DUAL_WRITE_START_AT
    """
    
    cutoff = MigrationConfig.DUAL_WRITE_START_AT
    
    followups = await db.followup_submissions.find({
        "submission_date": {"$lt": cutoff}
    }).to_list(100000)
    
    total = len(followups)
    migrated = 0
    skipped = 0
    errors = []
    
    for followup in followups:
        try:
            user_id = followup["user_id"]
            followup_id = followup["_id"]
            
            # CHECK DE IDEMPOTENCIA
            existing = await db.client_drawers.find_one({
                "user_id": user_id,
                "services.shared.questionnaires.followups.followup_id": followup_id
            })
            
            if existing:
                logger.info(f"‚è≠Ô∏è Skipped {followup_id}: already exists")
                skipped += 1
                continue
            
            # Separar secciones
            training_section = {
                "measurements": followup.get("measurements", {}),
                "adherence": followup.get("adherence", {}).get("training", {}),
                "changes_perceived": followup.get("changes_perceived", {}).get("training", {}),
                "feedback": followup.get("feedback", {}).get("training", {})
            }
            
            nutrition_section = {
                "adherence": followup.get("adherence", {}).get("nutrition", {}),
                "changes_perceived": followup.get("changes_perceived", {}).get("nutrition", {}),
                "feedback": followup.get("feedback", {}).get("nutrition", {})
            }
            
            # Resolver previous_snapshot_ids
            # (Buscar snapshots que generaron previous_plan_id)
            previous_training_snapshot = None
            previous_nutrition_snapshot = None
            # ... l√≥gica de resoluci√≥n
            
            followup_doc = {
                "followup_id": followup_id,
                "submitted_at": followup.get("submission_date"),
                "days_since_last": followup.get("days_since_last_plan", 30),
                "previous_snapshot_training_id": previous_training_snapshot,
                "previous_snapshot_nutrition_id": previous_nutrition_snapshot,
                "training_section": training_section,
                "nutrition_section": nutrition_section
            }
            
            # Push al drawer
            await db.client_drawers.update_one(
                {"user_id": user_id},
                {"$push": {"services.shared.questionnaires.followups": followup_doc}}
            )
            
            migrated += 1
        
        except Exception as e:
            logger.error(f"Error: {followup['_id']}: {e}")
            errors.append({"followup_id": followup["_id"], "error": str(e)})
    
    logger.info(f"Followups migration: {migrated}/{total}, skipped {skipped}, errors {len(errors)}")
    
    return {"total": total, "migrated": migrated, "skipped": skipped, "errors": errors}
```

---

#### 7.3. Vincular Planes Legacy

**Script:** `/app/backend/migration/scripts/04_link_legacy_plans.py`

```python
async def link_legacy_plans():
    """
    Actualizar training_plans y nutrition_plans con referencias a drawer.
    Crear snapshots retroactivos si es necesario.
    """
    
    # Planes sin snapshot_id
    legacy_plans = await db.training_plans.find({
        "snapshot_id": {"$exists": False}
    }).to_list(100000)
    
    for plan in legacy_plans:
        try:
            user_id = plan["user_id"]
            
            drawer = await db.client_drawers.find_one({"user_id": user_id})
            if not drawer:
                continue
            
            # Crear snapshot retroactivo
            version = len(drawer["services"]["training"]["snapshots"]) + 1
            
            snapshot = {
                "snapshot_id": f"snapshot_legacy_training_v{version}",
                "version": version,
                "created_at": plan.get("generated_at"),
                "trigger": "migrated_from_legacy",
                "client_context": {
                    "training": extract_training_context_from_plan(plan)
                },
                "plans_generated": {
                    "training_plan_id": plan["_id"]
                }
            }
            
            # A√±adir snapshot
            await db.client_drawers.update_one(
                {"user_id": user_id},
                {"$push": {"services.training.snapshots": snapshot}}
            )
            
            # Actualizar plan
            await db.training_plans.update_one(
                {"_id": plan["_id"]},
                {
                    "$set": {
                        "client_drawer_id": drawer["_id"],
                        "snapshot_id": snapshot["snapshot_id"]
                    }
                }
            )
        
        except Exception as e:
            logger.error(f"Error linking plan {plan['_id']}: {e}")
```

---

### ‚úÖ Validaci√≥n Post-Fase 2

**Script:** `/app/backend/migration/scripts/05_validate_migration.py`

```python
async def validate_migration():
    """Validaci√≥n exhaustiva de migraci√≥n"""
    
    # Contar legacy vs drawer
    legacy_count = await db.nutrition_questionnaire_submissions.count_documents({
        "submitted_at": {"$lt": MigrationConfig.DUAL_WRITE_START_AT}
    })
    
    drawer_count = await db.client_drawers.count_documents({
        "services.shared.questionnaires.inicial": {"$exists": True}
    })
    
    match_rate = drawer_count / legacy_count if legacy_count > 0 else 0
    
    print(f"Legacy submissions: {legacy_count}")
    print(f"Drawers migrated: {drawer_count}")
    print(f"Match rate: {match_rate * 100:.1f}%")
    
    # Umbral: 95%
    assert match_rate >= 0.95, f"Match rate too low: {match_rate}"
    
    # Verificar duplicados
    duplicates = await detect_duplicates_in_drawers()
    assert len(duplicates) == 0, "Duplicates detected"
    
    print("‚úÖ Validation PASSED")
```

---

### üîÑ Rollback Fase 2

Si falla:

```bash
# 1. Restaurar backup
mongorestore --uri="$MONGO_URL" --db="$DB_NAME" --drop /backups/pre_phase2_YYYYMMDD_HHMMSS/

# 2. Limpiar drawers parciales
mongo $MONGO_URL/$DB_NAME --eval "db.client_drawers.deleteMany({})"

# 3. Corregir scripts y re-ejecutar
```

**Tiempo:** 30-60 min

---

### ‚è±Ô∏è Duraci√≥n Estimada

**2-3 d√≠as** (seg√∫n volumen en staging)

---

## 8. FASE 3: SWITCH

### üéØ Objetivo

Cambiar lectura a `client_drawers`. **Momento m√°s cr√≠tico.**

---

### ‚ö†Ô∏è PRE-REQUISITOS

- ‚úÖ Fase 2 completada 100%
- ‚úÖ Validaci√≥n > 95%
- ‚úÖ Backup reciente (< 24h)
- ‚úÖ Equipo disponible para rollback

---

### üìã Tareas

#### 8.1. Modificar Orquestador

```python
# /app/backend/edn360/orchestrator.py

async def generate_initial_plan(self, job_id: str):
    """
    Generar plan.
    
    FASE 3: Lee de client_drawer.
    """
    
    job = await db.generation_jobs.find_one({"_id": job_id})
    
    if Config.USE_CLIENT_DRAWER_READ:
        # TO BE
        drawer = await db.client_drawers.find_one({"_id": job["client_drawer_id"]})
        
        # Leer cuestionario compartido
        questionnaire = drawer["services"]["shared"]["questionnaires"]["inicial"]
        
        # Pipeline training usa training_section
        training_data = questionnaire["training_section"]
        
        # Pipeline nutrition usa nutrition_section
        nutrition_data = questionnaire["nutrition_section"]
        
        # Ejecutar pipelines...
    else:
        # AS IS (legacy)
        # ...
```

---

#### 8.2. Activar Switch

```bash
# .env
USE_CLIENT_DRAWER_READ=true

# Reiniciar
sudo supervisorctl restart backend
```

---

#### 8.3. Monitoreo 48h

```python
@app.get("/admin/monitoring/switch-status")
async def get_switch_status():
    cutoff = datetime.now(timezone.utc) - timedelta(hours=24)
    
    recent_jobs = await db.generation_jobs.find({
        "created_at": {"$gte": cutoff}
    }).to_list(1000)
    
    to_be_jobs = [j for j in recent_jobs if "client_drawer_id" in j]
    success = [j for j in to_be_jobs if j["status"] == "completed"]
    
    return {
        "to_be_jobs": len(to_be_jobs),
        "success_rate": len(success) / len(to_be_jobs) if to_be_jobs else 0
    }
```

---

### ‚úÖ Criterios Fase 3

| **Criterio** | **Umbral** |
|---|---|
| Tasa √©xito jobs TO BE | > 95% |
| Sin errores cr√≠ticos | 0 |

---

### üîÑ Rollback Fase 3

```bash
# INMEDIATO
USE_CLIENT_DRAWER_READ=false
sudo supervisorctl restart backend
```

**Tiempo:** < 5 min

---

### ‚è±Ô∏è Duraci√≥n

**1 d√≠a + 48h monitoreo**

---

## 9. FASE 4: LIMPIEZA

### üéØ Objetivo

Eliminar c√≥digo legacy. **Solo tras estabilizaci√≥n completa.**

---

### üìã Tareas

#### 9.1. Deprecar Colecciones

```python
# /app/backend/migration/scripts/06_deprecate_collections.py

async def deprecate_legacy_collections():
    """Renombrar (NO eliminar) colecciones legacy"""
    
    date_suffix = datetime.now().strftime("%Y%m%d")
    
    collections = [
        "nutrition_questionnaire_submissions",
        "followup_submissions"
    ]
    
    for col in collections:
        new_name = f"{col}_DEPRECATED_{date_suffix}"
        await db[col].rename(new_name)
        print(f"‚úÖ Deprecated: {col} ‚Üí {new_name}")
    
    print("‚ö†Ô∏è Can be deleted after 30 days if no issues")
```

---

#### 9.2. Eliminar C√≥digo Legacy

Archivos a modificar:
- `/app/backend/server.py` (eliminar endpoints legacy)
- `/app/backend/edn360/orchestrator.py` (eliminar branch AS IS)
- `/app/backend/config.py` (eliminar feature flags)

---

### ‚è±Ô∏è Duraci√≥n

**2-3 d√≠as**

---

## 10. UMBRALES Y ACCIONES

### üìä Tabla de Decisi√≥n Operativa

Esta tabla es un **√°rbol de decisi√≥n obligatorio**. No admite interpretaciones.

| **M√©trica** | **Umbral / Resultado** | **Acci√≥n Obligatoria** | **Responsable** |
|---|---|---|---|
| **Match rate cuestionarios** | < 90% | Rollback Fase 2 completo | Equipo Dev |
| **Match rate cuestionarios** | 90‚Äì95% | Revisar casos fallidos, corregir, revalidar antes de avanzar | Equipo Dev + Jorge |
| **Match rate cuestionarios** | ‚â• 95% | ‚úÖ OK para avanzar a Fase 3 | Jorge aprueba |
| **Match rate followups** | < 90% | Rollback Fase 2 | Equipo Dev |
| **Match rate followups** | 90‚Äì95% | Revisar y corregir | Equipo Dev + Jorge |
| **Match rate followups** | ‚â• 95% | ‚úÖ OK | Jorge aprueba |
| **Planes sin snapshot_id** | > 0 | Bloquear avance hasta resolver a 0 | Equipo Dev |
| **Errores cr√≠ticos en script** | ‚â• 1 | Pausar todo hasta resoluci√≥n | Equipo Dev |
| **Duplicados detectados** | > 0 | Pausa inmediata + an√°lisis de causa | Equipo Dev |
| **Tasa √©xito jobs TO BE (Fase 3)** | < 90% | Rollback Fase 3 inmediato | Jorge + Equipo Dev |
| **Tasa √©xito jobs TO BE (Fase 3)** | 90‚Äì95% | Investigar errores, no avanzar hasta > 95% | Equipo Dev |
| **Tasa √©xito jobs TO BE (Fase 3)** | ‚â• 95% | ‚úÖ OK, continuar monitoreo 48h | Jorge aprueba |

---

### üö® Acciones Inmediatas ante Fallo

#### Escenario 1: Match Rate < 90% en Fase 2

**Acci√≥n:**
1. DETENER migraci√≥n inmediatamente
2. Ejecutar rollback Fase 2
3. Analizar errores en logs
4. Corregir scripts
5. Re-ejecutar en staging
6. Solicitar re-aprobaci√≥n a Jorge

---

#### Escenario 2: Duplicados Detectados

**Acci√≥n:**
1. PAUSA INMEDIATA de migraci√≥n
2. Ejecutar script de detecci√≥n:
   ```python
   duplicates = await detect_duplicates_in_drawers()
   ```
3. Analizar causa ra√≠z
4. Eliminar duplicados manualmente si es posible
5. Corregir script para evitar recurrencia
6. Re-validar

---

#### Escenario 3: Tasa √âxito < 90% en Fase 3

**Acci√≥n:**
1. Rollback inmediato (desactivar `USE_CLIENT_DRAWER_READ`)
2. Analizar logs de jobs fallidos
3. Identificar causa (¬ødatos faltantes? ¬øerror de c√≥digo?)
4. Corregir
5. Re-aprobar con Jorge antes de reactivar

---

## 11. LISTADO SCRIPTS

### üìÇ Estructura de Scripts

```
/app/backend/migration/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ 00_create_collection.py
‚îÇ   ‚îú‚îÄ‚îÄ 01_enable_dual_write.py
‚îÇ   ‚îú‚îÄ‚îÄ 02_migrate_questionnaires.py
‚îÇ   ‚îú‚îÄ‚îÄ 03_migrate_followups.py
‚îÇ   ‚îú‚îÄ‚îÄ 04_link_legacy_plans.py
‚îÇ   ‚îú‚îÄ‚îÄ 05_validate_migration.py
‚îÇ   ‚îú‚îÄ‚îÄ 06_deprecate_collections.py
‚îÇ   ‚îî‚îÄ‚îÄ 07_rollback_phase_2.py
‚îú‚îÄ‚îÄ helpers/
‚îÇ   ‚îú‚îÄ‚îÄ migration_helpers.py
‚îÇ   ‚îî‚îÄ‚îÄ duplicate_detector.py
‚îî‚îÄ‚îÄ config.py
```

---

### üìã Detalle de Scripts

#### **00_create_collection.py**

**Objetivo:** Crear colecci√≥n `client_drawers` con √≠ndices

**Entradas:** N/A

**Salidas:**
- Colecci√≥n `client_drawers` creada
- 4 √≠ndices creados

**Riesgos:** Ninguno (sin impacto en prod)

**Criterio de √©xito:** Colecci√≥n existe y tiene √≠ndices

---

#### **01_enable_dual_write.py**

**Objetivo:** Activar escritura dual AS IS + TO BE

**Entradas:**
- Feature flag `USE_CLIENT_DRAWER_WRITE`
- Timestamp `DUAL_WRITE_START_AT`

**Salidas:**
- Nuevos cuestionarios se escriben en ambos sistemas
- Validaciones en background

**Riesgos:** Bajo (AS IS sigue funcionando si TO BE falla)

**Criterio de √©xito:** Match rate > 98%

---

#### **02_migrate_questionnaires.py**

**Objetivo:** Migrar cuestionarios iniciales hist√≥ricos

**Entradas:**
- Colecci√≥n `nutrition_questionnaire_submissions`
- Filtro: `submitted_at < DUAL_WRITE_START_AT`

**Salidas:**
- Drawers con `services.shared.questionnaires.inicial` poblado

**Riesgos:** MEDIO
- Puede generar duplicados si no se valida idempotencia
- Timeout en batches grandes

**Criterio de √©xito:**
- Match rate ‚â• 95%
- 0 duplicados

---

#### **03_migrate_followups.py**

**Objetivo:** Migrar seguimientos hist√≥ricos

**Entradas:**
- Colecci√≥n `followup_submissions`
- Filtro: `submission_date < DUAL_WRITE_START_AT`

**Salidas:**
- Drawers con `services.shared.questionnaires.followups[]` poblado

**Riesgos:** MEDIO
- Resolver `previous_snapshot_id` puede fallar si no hay snapshot

**Criterio de √©xito:**
- Match rate ‚â• 95%
- 0 duplicados

---

#### **04_link_legacy_plans.py**

**Objetivo:** Vincular planes legacy con snapshots

**Entradas:**
- Colecciones `training_plans`, `nutrition_plans`
- Drawers existentes

**Salidas:**
- Planes con `snapshot_id` y `client_drawer_id`
- Snapshots retroactivos creados

**Riesgos:** BAJO
- Snapshot retroactivo puede ser incompleto

**Criterio de √©xito:**
- 0 planes sin `snapshot_id`

---

#### **05_validate_migration.py**

**Objetivo:** Validaci√≥n exhaustiva post-migraci√≥n

**Entradas:**
- Drawers migrados
- Datos legacy

**Salidas:**
- Informe de validaci√≥n con match rates

**Riesgos:** Ninguno (solo lectura)

**Criterio de √©xito:**
- Todos los match rates > 95%
- 0 duplicados

---

#### **06_deprecate_collections.py**

**Objetivo:** Renombrar colecciones legacy

**Entradas:**
- Colecciones legacy

**Salidas:**
- Colecciones renombradas `*_DEPRECATED_YYYYMMDD`

**Riesgos:** BAJO (rename reversible)

**Criterio de √©xito:**
- Colecciones renombradas correctamente

---

#### **07_rollback_phase_2.py**

**Objetivo:** Restaurar desde backup

**Entradas:**
- Path del backup

**Salidas:**
- BD restaurada al estado pre-migraci√≥n

**Riesgos:** MEDIO
- Pierde datos creados entre backup y rollback

**Criterio de √©xito:**
- BD restaurada correctamente

---

## 12. PLAN ROLLBACK

### üîÑ Rollback por Fase

| **Fase** | **Dificultad** | **Tiempo** | **Procedimiento** |
|---|---|---|---|
| Fase 0 | F√°cil | N/A | Sin impacto, rehacer |
| Fase 1 | F√°cil | 2 min | Desactivar `USE_CLIENT_DRAWER_WRITE` |
| Fase 2 | Media | 30-60 min | Restaurar backup + limpiar drawers |
| Fase 3 | Media | 2-5 min | Desactivar `USE_CLIENT_DRAWER_READ` |
| Fase 4 | N/A | N/A | Sistema estabilizado |

---

### üö® Procedimientos Detallados

#### Rollback Fase 1

```bash
# 1. Desactivar dual-write
echo "USE_CLIENT_DRAWER_WRITE=false" >> /app/backend/.env

# 2. Reiniciar
sudo supervisorctl restart backend

# 3. Verificar
curl http://localhost:8001/api/admin/monitoring/dual-write-stats
```

---

#### Rollback Fase 2

```bash
# 1. Restaurar backup
mongorestore --uri="$MONGO_URL" --db="$DB_NAME" --drop /backups/pre_phase2_YYYYMMDD_HHMMSS/

# 2. Limpiar client_drawers
mongo $MONGO_URL/$DB_NAME --eval "db.client_drawers.deleteMany({})"

# 3. Verificar
mongo $MONGO_URL/$DB_NAME --eval "db.client_drawers.count()"
# Debe ser 0

# 4. Corregir scripts
# ... an√°lisis de errores

# 5. Re-ejecutar en staging
```

---

#### Rollback Fase 3

```bash
# 1. INMEDIATO: Desactivar lectura TO BE
echo "USE_CLIENT_DRAWER_READ=false" >> /app/backend/.env

# 2. Reiniciar
sudo supervisorctl restart backend

# 3. Verificar que volvi√≥ a AS IS
curl http://localhost:8001/api/admin/monitoring/switch-status
# Debe mostrar USE_CLIENT_DRAWER_READ=false
```

---

## 13. SUPERVISI√ìN JORGE

### üë§ Puntos de Intervenci√≥n Manual

Jorge debe intervenir en los siguientes puntos:

---

#### Punto 1: Aprobaci√≥n GO Fase 0.5 ‚Üí Fase 2

**Cu√°ndo:** Tras completar staging

**Qu√© revisar:**
- Informe de staging completo
- M√©tricas de tiempo reales
- Match rates en staging
- Errores y correcciones aplicadas

**Acci√≥n:** Aprobar o rechazar paso a producci√≥n

---

#### Punto 2: Validaci√≥n Manual Pre-Fase 2

**Cu√°ndo:** Antes de ejecutar migraci√≥n en producci√≥n

**Qu√© revisar:**
- Muestra aleatoria de 5 clientes:
  - Ver cuestionario inicial en AS IS
  - Ver historial de seguimientos
  - Ver planes hist√≥ricos (training + nutrition)

**Acci√≥n:** Confirmar que datos son correctos

---

#### Punto 3: Aprobaci√≥n GO Fase 2 ‚Üí Fase 3

**Cu√°ndo:** Tras completar Fase 2 y validaci√≥n

**Qu√© revisar:**
- Match rates post-migraci√≥n
- Informe de duplicados (debe ser 0)
- Muestra aleatoria de 5 clientes post-migraci√≥n:
  - Ver drawer completo
  - Comparar con datos legacy
  - Verificar coherencia

**Acci√≥n:** Aprobar o rechazar switch

---

#### Punto 4: Validaci√≥n Manual Post-Fase 3

**Cu√°ndo:** Tras activar switch (primeras 24h)

**Qu√© revisar:**
- Generar 3 planes de prueba con clientes reales
- Revisar que:
  - Objetivo es correcto
  - Plan tiene coherencia
  - Historial del cliente visible

**Acci√≥n:** Aprobar continuar o solicitar rollback

---

#### Punto 5: Aprobaci√≥n Cierre Fase 4

**Cu√°ndo:** Tras estabilizaci√≥n completa

**Qu√© revisar:**
- Informe final de migraci√≥n
- M√©tricas de performance
- Colecciones legacy deprecadas

**Acci√≥n:** Aprobar cierre formal de migraci√≥n

---

## 14. CIERRE T√âCNICO

### ‚úÖ Criterios de Cierre

La migraci√≥n se considera **completada t√©cnicamente** cuando:

1. ‚úÖ **Agentes leen exclusivamente de `client_drawers`:**
   - C√≥digo legacy eliminado
   - Feature flags removidos
   - Sin referencias a colecciones legacy en c√≥digo

2. ‚úÖ **Colecciones legacy deprecadas:**
   - Renombradas con sufijo `_DEPRECATED_YYYYMMDD`
   - Documentado que pueden eliminarse tras 30 d√≠as

3. ‚úÖ **Informe final de migraci√≥n creado:**
   ```
   Informe Final de Migraci√≥n EDN360
   ==================================
   
   Fecha de inicio: 1 Febrero 2025
   Fecha de cierre: 15 Marzo 2025
   Duraci√≥n total: 6 semanas
   
   M√©tricas:
   - Cuestionarios migrados: 15,180 / 15,234 (99.6%)
   - Followups migrados: 8,420 / 8,456 (99.5%)
   - Planes vinculados: 25,700 / 25,780 (99.7%)
   - Duplicados detectados: 0
   
   Incidencias:
   - 3 errores menores corregidos en staging
   - 0 incidencias en producci√≥n
   
   Acciones correctoras:
   - Ajuste de timeout en script 02
   - √çndice adicional en submitted_at
   
   Performance:
   - Tiempo generaci√≥n plan: 85s (antes 90s, mejora 5%)
   - Queries historial: 1 query (antes 5+, mejora 80%)
   
   Estado: ‚úÖ COMPLETADO
   ```

4. ‚úÖ **Tests de regresi√≥n pasan:**
   - Generaci√≥n de planes funciona
   - Historial accesible
   - Seguimientos funcionan

5. ‚úÖ **Jorge aprueba formalmente:**
   - Revisi√≥n del informe
   - Aprobaci√≥n escrita en documento

---

### üìù Documentaci√≥n Final

Al cierre, debe existir:

1. **DOCUMENTO 2 vFINAL** (aprobado)
2. **DOCUMENTO 3 v2** (este documento, aprobado)
3. **Informe de Staging** (con m√©tricas reales)
4. **Informe Final de Migraci√≥n** (con m√©tricas de producci√≥n)
5. **Logs de migraci√≥n** (guardados en BD)

---

## üìù RESUMEN EJECUTIVO

### üéØ Objetivo

Migrar EDN360 de AS IS a TO BE (client_drawer) en **6-7 semanas** sin p√©rdida de datos ni downtime.

---

### üìä Fases

0. **Preparaci√≥n** (3-5 d√≠as)
0.5. **STAGING** (5-7 d√≠as) ‚ö†Ô∏è OBLIGATORIA
1. **Coexistencia** (1-2 semanas)
2. **Migraci√≥n** (2-3 d√≠as)
3. **Switch** (1 d√≠a + 48h)
4. **Limpieza** (2-3 d√≠as)

---

### üîí Seguridad

- Backups antes de cada fase cr√≠tica
- Feature flags para rollback r√°pido
- Validaci√≥n exhaustiva (umbrales > 95%)
- Plan de rollback documentado

---

### üë• Responsabilidades

- **Equipo Dev:** Ejecuci√≥n t√©cnica, monitoreo, rollback
- **Jorge:** Validaci√≥n de muestras, aprobaci√≥n GO/NO-GO, decisi√≥n rollback

---

### ‚úÖ Aprobaci√≥n

**Este manual operativo requiere aprobaci√≥n formal de Jorge Calcerrada antes de iniciar ejecuci√≥n.**

---

**Fin del Manual Operativo**
